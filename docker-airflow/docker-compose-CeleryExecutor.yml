
services:

    zookeeper:
        image: 'confluentinc/cp-zookeeper:7.4.0'
        hostname: zookeeper
        container_name: zookeeper
        ports:
            - '2181:2181'
        environment:
            ZOOKEEPER_CLIENT_PORT: 2181
            ZOOKEEPER_TICK_TIME: 2000
        healthcheck:
            test: ['CMD', 'bash', '-c', "echo 'ruok' | nc localhost 2181"]
            interval: 10s
            timeout: 5s
            retries: 5
        networks:
            - confluent
    broker:
        image: 'confluentinc/cp-server:7.4.0'
        hostname: broker
        container_name: broker
        depends_on:
            zookeeper:
                condition: service_healthy
        ports:
            - '9092:9092'
            - '9101:9101'
        environment:
            KAFKA_BROKER_ID: 1
            KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
            KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
            KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
            KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
            KAFKA_JMX_PORT: 9101
            KAFKA_JMX_HOSTNAME: localhost
            KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
            CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker:29092
            CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
            CONFLUENT_METRICS_ENABLE: 'false'
            CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
        networks:
            - confluent
        healthcheck:
            test: ['CMD', 'bash', '-c', 'nc -z localhost 9092']
            interval: 10s
            timeout: 5s
            retries: 5
    
    schema-registry:
        image: confluentinc/cp-schema-registry:7.4.0
        hostname: schema-registry
        container_name: schema-registry
        depends_on:
            broker:
                condition: service_healthy
        ports:
            - '8081:8081'
        environment:
            SCHEMA_REGISTRY_HOST_NAME: schema-registry
            SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker:29092'
            SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
        networks:
            - confluent
        healthcheck:
            test: ['CMD', 'curl', '-f', 'http://localhost:8081']
            interval: 30s
            timeout: 10s
            retries: 5
    
    control-center:
        image: confluentinc/cp-enterprise-control-center:7.4.0
        hostname: control-center
        container_name: control-center
        depends_on:
            broker:
                condition: service_healthy
            schema-registry:
                condition: service_healthy
        ports:
            - "9021:9021"
        environment:
            CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:29092'
            CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
            CONTROL_CENTER_REPLICATION_FACTOR: 1
            CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
            CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
            CONFLUENT_METRICS_TOPIC_REPLICATION: 1
            CONFLUENT_METRICS_ENABLE: 'false'
            PORT: 9021
        networks:
            - confluent
        


    redis:
        image: 'redis:5.0.5'
        # command: redis-server --requirepass redispass
        networks:
            - confluent

    postgres:
        image: postgres:9.6
        networks:
            - confluent
        environment:
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=airflow
            - POSTGRES_DB=airflow
        # Uncomment these lines to persist data on the local filesystem.
        #     - PGDATA=/var/lib/postgresql/data/pgdata
        # volumes:
        #     - ./pgdata:/var/lib/postgresql/data/pgdata

    webserver:
        image: puckel/docker-airflow:1.10.9
        restart: always
        networks:
            - confluent
        depends_on:
            - postgres
            - redis
        environment:
            - LOAD_EX=n
            - FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
            - EXECUTOR=Celery
            # - POSTGRES_USER=airflow
            # - POSTGRES_PASSWORD=airflow
            # - POSTGRES_DB=airflow
            # - REDIS_PASSWORD=redispass
        volumes:
            - ./dags:/usr/local/airflow/dags
            # Uncomment to include custom plugins
            # - ./plugins:/usr/local/airflow/plugins
        ports:
            - "8080:8080"
        command: webserver
        healthcheck:
            test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
            interval: 30s
            timeout: 30s
            retries: 3

    flower:
        image: puckel/docker-airflow:1.10.9
        restart: always
        networks:
            - confluent
        depends_on:
            - redis
        environment:
            - EXECUTOR=Celery
            # - REDIS_PASSWORD=redispass
        ports:
            - "5555:5555"
        command: flower

    scheduler:
        image: puckel/docker-airflow:1.10.9
        restart: always
        networks:
            - confluent
        depends_on:
            - webserver
        volumes:
            - ./dags:/usr/local/airflow/dags
            # Uncomment to include custom plugins
            # - ./plugins:/usr/local/airflow/plugins
        environment:
            - LOAD_EX=n
            - FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
            - EXECUTOR=Celery
            # - POSTGRES_USER=airflow
            # - POSTGRES_PASSWORD=airflow
            # - POSTGRES_DB=airflow
            # - REDIS_PASSWORD=redispass
        command: scheduler

    worker:
        image: puckel/docker-airflow:1.10.9
        restart: always
        networks:
            - confluent
        depends_on:
            - scheduler
        volumes:
            - ./dags:/usr/local/airflow/dags
            # Uncomment to include custom plugins
            # - ./plugins:/usr/local/airflow/plugins
        environment:
            - FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
            - EXECUTOR=Celery
            # - POSTGRES_USER=airflow
            # - POSTGRES_PASSWORD=airflow
            # - POSTGRES_DB=airflow
            # - REDIS_PASSWORD=redispass
        command: worker
    spark-master:
        image: bitnami/spark:latest
        command: bin/spark-class org.apache.spark.deploy.master.Master
        ports:
            - "9090:8080"
            - "7077:7077"
        networks:
            - confluent
    spark-worker:
        image: bitnami/spark:latest
        command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
        depends_on:
            - spark-master
        environment:
            SPARK_MODE: worker
            SPARK_WORKER_CORES: 2
            SPARK_WORKER_MEMORY: 1g
            SPARK_MASTER_URL: spark://spark-master:7077
        networks:
            - confluent
    cassandra_db:
        image: cassandra:latest
        container_name: cassandra
        hostname: cassandra
        ports:
            - "9042:9042"
        environment:
            - MAX_HEAP_SIZE=512M
            - HEAP_NEWSIZE=100M
            - CASSANDRA_USERNAME=cassandra
            - CASSANDRA_PASSWORD=cassandra
        volumes:
            - ./:/home
        networks:
            - confluent
networks:
    confluent:
        external: true
        name: docker-airflow_confluent